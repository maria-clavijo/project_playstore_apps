{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Pruning\n",
    "\n",
    "We decide to prune the following features:\n",
    "\n",
    "App Name : App names are of no value for the model\n",
    "Released:   \n",
    "Last Updated : The informations it stores is same as the feature Category\n",
    "Size : Current Version of an app doesn't hold significant value.\n",
    "Minimum Android: Android Version of an app doesn't hold significant value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                App Name      Category Installs  Size Minimum Android  \\\n",
      "0                Gakondo     Adventure      10+   10M      7.1 and up   \n",
      "1    Ampere Battery Info         Tools   5,000+  2.9M      5.0 and up   \n",
      "2                 Vibook  Productivity      50+  3.7M    4.0.3 and up   \n",
      "3                 IMOCCI        Social      50+   46M      6.0 and up   \n",
      "4  The Everyday Calendar     Lifestyle     500+   16M      5.0 and up   \n",
      "\n",
      "       Released  Last Updated Content Rating  Rating  Minimum Installs  \\\n",
      "0  Feb 26, 2020  Feb 26, 2020       Everyone     0.0                10   \n",
      "1  May 21, 2020  May 06, 2021       Everyone     4.4               100   \n",
      "2   Aug 9, 2019  Aug 19, 2019       Everyone     0.0                50   \n",
      "3  Dec 24, 2018  Dec 20, 2019           Teen     0.0                50   \n",
      "4  Jun 21, 2019  Jun 21, 2019       Everyone     2.0               500   \n",
      "\n",
      "   Maximum Installs  \n",
      "0                15  \n",
      "1              7662  \n",
      "2                58  \n",
      "3                89  \n",
      "4               702  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the cleaned CSV file\n",
    "df_apps = pd.read_csv(r\"C:\\Users\\USER\\OneDrive - Universidad Autonoma de Occidente\\1. Ing. IAED\\Semestre V\\ETL\\project_playstore_apps\\data\\Google-Playstore-Dataset-Clean.csv\")\n",
    "\n",
    "# Show the first rows of the DataFrame\n",
    "print(df_apps.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_features = ['App Name', 'Released', 'Last Updated', 'Minimum Android']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2 | Data Splitting for Modeling\n",
    "\n",
    "We decide to split the dataset into 80% train and 20% test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Rating'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy().drop(pruned_features+[target], axis=1)\n",
    "y = df.copy()[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_dict = defaultdict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_encode = X_train.select_dtypes(include=['category', 'object']).columns\n",
    "\n",
    "for col in features_to_encode:\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    X_train[col] = le.fit_transform(X_train[col]) # Fitting and tranforming the Train data\n",
    "    X_train[col] = X_train[col].astype('category') # Converting the label encoded features from numerical back to categorical dtype in pandas\n",
    "\n",
    "    X_test[col] = le.transform(X_test[col]) # Only transforming the test data\n",
    "    X_test[col] = X_test[col].astype('category') # Converting the label encoded features from numerical back to categorical dtype in pandas\n",
    "\n",
    "    le_dict[col] = le # Saving the label encoder for individual features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting and adding \"Last Updated Month\" to categorical features\n",
    "categorical_features = features_to_encode + ['Updated_Month']\n",
    "X_train['Updated_Month'] = X_train['Updated_Month'].astype('category')\n",
    "X_test['Updated_Month'] = X_test['Updated_Month'].astype('category')\n",
    "\n",
    "# Listing numeric features to scale\n",
    "numeric_features = X_train.select_dtypes(exclude=['category', 'object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# Fitting and transforming the Training data\n",
    "X_train[numeric_features] = scaler.fit_transform(X_train[numeric_features])\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "# Only transforming the Test data\n",
    "X_test[numeric_features] = scaler.transform(X_test[numeric_features])\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3 | Modeling\n",
    "\n",
    "Step 7.1 | Regression\n",
    "Creating dataframe for metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['Linear', 'KNN', 'Random Forest']\n",
    "datasets = ['train', 'test']\n",
    "metrics = ['RMSE', 'MAE', 'R2']\n",
    "\n",
    "multi_index = pd.MultiIndex.from_product([models, datasets, metrics],\n",
    "                                         names=['model', 'dataset', 'metric'])\n",
    "\n",
    "df_metrics_reg = pd.DataFrame(index=multi_index,\n",
    "                          columns=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_reg.loc['Linear', 'train', 'R2'] = lr.score(X_train, y_train)\n",
    "df_metrics_reg.loc['Linear', 'test', 'R2'] = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "df_metrics_reg.loc['Linear', 'train', 'MAE'] = mean_absolute_error(y_train, y_train_pred)\n",
    "df_metrics_reg.loc['Linear', 'test', 'MAE'] = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "df_metrics_reg.loc['Linear', 'train', 'RMSE'] = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "df_metrics_reg.loc['Linear', 'test', 'RMSE'] = mean_squared_error(y_test, y_test_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighbors Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsRegressor()\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_reg.loc['KNN', 'train', 'R2'] = knn.score(X_train, y_train)\n",
    "df_metrics_reg.loc['KNN', 'test', 'R2'] = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = knn.predict(X_train)\n",
    "y_test_pred = knn.predict(X_test)\n",
    "\n",
    "df_metrics_reg.loc['KNN', 'train', 'MAE'] = mean_absolute_error(y_train, y_train_pred)\n",
    "df_metrics_reg.loc['KNN', 'test', 'MAE'] = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "df_metrics_reg.loc['KNN', 'train', 'RMSE'] = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "df_metrics_reg.loc['KNN', 'test', 'RMSE'] = mean_squared_error(y_test, y_test_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics_reg.loc['Random Forest', 'train', 'R2'] = rf.score(X_train, y_train)\n",
    "df_metrics_reg.loc['Random Forest', 'test', 'R2'] = rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf.predict(X_train)\n",
    "y_test_pred = rf.predict(X_test)\n",
    "\n",
    "df_metrics_reg.loc['Random Forest', 'train', 'MAE'] = mean_absolute_error(y_train, y_train_pred)\n",
    "df_metrics_reg.loc['Random Forest', 'test', 'MAE'] = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "df_metrics_reg.loc['Random Forest', 'train', 'RMSE'] = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "df_metrics_reg.loc['Random Forest', 'test', 'RMSE'] = mean_squared_error(y_test, y_test_pred, squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rounding the values\n",
    "\n",
    "df_metrics_reg['value'] = df_metrics_reg['value'].apply(lambda v: round(v, ndigits=3))\n",
    "df_metrics_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_metrics_reg.reset_index()\n",
    "\n",
    "g = sns.catplot(col='dataset', data=data, kind='bar', x='model', y='value', hue='metric')\n",
    "\n",
    "# Adding annotations to bars\n",
    "# iterate through axes\n",
    "for ax in g.axes.ravel():\n",
    "    # add annotations\n",
    "    for c in ax.containers:\n",
    "        ax.bar_label(c, label_type='edge')\n",
    "\n",
    "    ax.margins(y=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
